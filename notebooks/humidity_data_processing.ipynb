{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humidity Data Processing\n",
    "This notebook loads raw humidity data, handles missing values, cleans timestamp formats, and exports a processed dataset ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "RAW_DEMAND_DIR = \"data/raw/demand\"\n",
    "RAW_WEATHER_DIR = \"data/raw/weather\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "\n",
    "STATES = [\"VIC\", \"NSW\", \"QLD\", \"SA\", \"TAS\"]\n",
    "\n",
    "# Map REGION codes in AEMO data to clean state names\n",
    "REGION_TO_STATE = {\n",
    "    \"NSW1\": \"NSW\",\n",
    "    \"QLD1\": \"QLD\",\n",
    "    \"SA1\":  \"SA\",\n",
    "    \"TAS1\": \"TAS\",\n",
    "    \"VIC1\": \"VIC\",\n",
    "}\n",
    "\n",
    "WEATHER_FILES = {\n",
    "    \"VIC\": [\"HM01X_Data_086338_999999999743964.txt\",\"HM01X_Data_086338_999999999743964.txt\"],\n",
    "    \"NSW\": [\"HM01X_Data_066062_999999999743964.txt\"],\n",
    "    \"QLD\": [\"HM01X_Data_040913_999999999743964.txt\"],\n",
    "    \"SA\":  [\"HM01X_Data_023090_999999999743964.txt\"],\n",
    "    \"TAS\": [\"HM01X_Data_094029_999999999743964.txt\"],\n",
    "}\n",
    "\n",
    "# Rename columns & variables\n",
    "WEATHER_DATETIME_COLS = {\n",
    "    \"year\":   \"Year Month Day Hour Minutes in YYYY\",\n",
    "    \"month\":  \"MM\",\n",
    "    \"day\":    \"DD\",\n",
    "    \"hour\":   \"HH24\",\n",
    "    \"minute\": \"MI format in Local time\",\n",
    "}\n",
    "\n",
    "HUMIDITY_RAW_COL = \"Relative humidity in percentage %\"\n",
    "TEMP_RAW_COL     = \"Air Temperature in degrees C\"\n",
    "\n",
    "HUMIDITY_COL = \"Humidity (%)\"\n",
    "TEMP_COL     = \"Temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions to Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demand_for_state(state: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Read and combine all raw demand CSVs for a single state.\n",
    "    Renames columns and parses Datetime.\n",
    "    \"\"\"\n",
    "    pattern = os.path.join(RAW_DEMAND_DIR, f\"*{state}*.csv\")\n",
    "    demand_files = sorted(glob.glob(pattern))\n",
    "\n",
    "    if not demand_files:\n",
    "        print(f\"[WARN] No demand files found for {state} (pattern: {pattern})\")\n",
    "        return None\n",
    "\n",
    "    df_list = [pd.read_csv(f) for f in demand_files]\n",
    "    demand_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    demand_df = demand_df.rename(\n",
    "        columns={\n",
    "            \"SETTLEMENTDATE\": \"Datetime\",\n",
    "            \"TOTALDEMAND\": \"Total Demand\",\n",
    "            \"REGION\": \"State\",\n",
    "        }\n",
    "    )\n",
    "    demand_df = demand_df.drop(columns=[\"PERIODTYPE\"], errors=\"ignore\")\n",
    "\n",
    "    # Parse datetime\n",
    "    demand_df[\"Datetime\"] = pd.to_datetime(demand_df[\"Datetime\"], format=\"mixed\", utc=True)\n",
    "\n",
    "    # Map REGION codes\n",
    "    demand_df[\"State\"] = demand_df[\"State\"].replace(REGION_TO_STATE)\n",
    "\n",
    "    # Drop timezone for merging with local BOM timestamps\n",
    "    demand_df[\"Datetime\"] = demand_df[\"Datetime\"].dt.tz_localize(None)\n",
    "\n",
    "    print(f\"[INFO] Demand for {state}: {demand_df.shape}\")\n",
    "    return demand_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather_for_state(state: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Read and combine BOM weather files for a single state,\n",
    "    construct Datetime, and keep only humidity + temperature.\n",
    "    \"\"\"\n",
    "    filenames = WEATHER_FILES.get(state, [])\n",
    "    if not filenames:\n",
    "        print(f\"[WARN] No weather files configured for {state} in WEATHER_FILES.\")\n",
    "        return None\n",
    "\n",
    "    dfs = []\n",
    "    for fname in filenames:\n",
    "        path = os.path.join(RAW_WEATHER_DIR, fname)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[WARN] Weather file not found: {path}\")\n",
    "            continue\n",
    "        dfs.append(pd.read_csv(path))\n",
    "\n",
    "    if not dfs:\n",
    "        print(f\"[WARN] No weather data actually loaded for {state}.\")\n",
    "        return None\n",
    "\n",
    "    weather_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Build Datetime from BOM columns\n",
    "    weather_df[\"Datetime\"] = pd.to_datetime(\n",
    "        {\n",
    "            \"year\":   weather_df[WEATHER_DATETIME_COLS[\"year\"]],\n",
    "            \"month\":  weather_df[WEATHER_DATETIME_COLS[\"month\"]],\n",
    "            \"day\":    weather_df[WEATHER_DATETIME_COLS[\"day\"]],\n",
    "            \"hour\":   weather_df[WEATHER_DATETIME_COLS[\"hour\"]],\n",
    "            \"minute\": weather_df[WEATHER_DATETIME_COLS[\"minute\"]],\n",
    "        },\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    # Drop timezone to match demand_df\n",
    "    weather_df[\"Datetime\"] = weather_df[\"Datetime\"].dt.tz_localize(None)\n",
    "\n",
    "    # Check required columns exist\n",
    "    missing_cols = [c for c in [HUMIDITY_RAW_COL, TEMP_RAW_COL] if c not in weather_df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"[WARN] Missing columns for {state}: {missing_cols}\")\n",
    "        print(\"Available columns:\", list(weather_df.columns)[:15], \"...\")\n",
    "        return None\n",
    "\n",
    "    # Rename raw cols -> clean cols\n",
    "    weather_df = weather_df.rename(\n",
    "        columns={\n",
    "            HUMIDITY_RAW_COL: HUMIDITY_COL,\n",
    "            TEMP_RAW_COL: TEMP_COL,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Keep only Datetime + humidity + temperature\n",
    "    weather_df = weather_df[[\"Datetime\", HUMIDITY_COL, TEMP_COL]]\n",
    "\n",
    "    # Convert to numeric\n",
    "    weather_df[HUMIDITY_COL] = pd.to_numeric(weather_df[HUMIDITY_COL], errors=\"coerce\")\n",
    "    weather_df[TEMP_COL] = pd.to_numeric(weather_df[TEMP_COL], errors=\"coerce\")\n",
    "\n",
    "    # Sort by Datetime\n",
    "    weather_df = weather_df.sort_values(\"Datetime\")\n",
    "\n",
    "    print(f\"[INFO] Weather (Humidity+Temp) for {state}: {weather_df.shape}\")\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Function to Merge and Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state(state: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Full pipeline for one state:\n",
    "    - load demand\n",
    "    - load humidity (only)\n",
    "    - inner merge on Datetime\n",
    "    - save to data/processed/{STATE}_clean.csv\n",
    "    \"\"\"\n",
    "    demand_df = load_demand_for_state(state)\n",
    "    humidity_df = load_weather_for_state(state)\n",
    "\n",
    "    if demand_df is None or humidity_df is None:\n",
    "        print(f\"[WARN] Skipping {state} because demand or humidity is missing.\")\n",
    "        return None\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        demand_df,\n",
    "        humidity_df,\n",
    "        on=\"Datetime\",\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    out_path = os.path.join(PROCESSED_DIR, f\"{state}_clean.csv\")\n",
    "    merged_df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"[OK] {state}: saved {out_path}, shape={merged_df.shape}\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Files & Build Master File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Demand for VIC: (350632, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,16,22,24,26,28,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n",
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,16,22,24,26,28,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Weather (Humidity+Temp) for VIC: (238886, 3)\n",
      "[OK] VIC: saved data/processed/VIC_clean.csv, shape=(230880, 6)\n",
      "[INFO] Demand for NSW: (350632, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,14,18,20,28,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Weather (Humidity+Temp) for NSW: (350945, 3)\n",
      "[OK] NSW: saved data/processed/NSW_clean.csv, shape=(349699, 6)\n",
      "[INFO] Demand for QLD: (350632, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,14,18,20,22,24,26,28,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Weather (Humidity+Temp) for QLD: (350977, 3)\n",
      "[OK] QLD: saved data/processed/QLD_clean.csv, shape=(349294, 6)\n",
      "[INFO] Demand for SA: (350632, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,14,18,20,22,24,26,28,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Weather (Humidity+Temp) for SA: (355906, 3)\n",
      "[OK] SA: saved data/processed/SA_clean.csv, shape=(349176, 6)\n",
      "[INFO] Demand for TAS: (256437, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/qf_dfhwn3vjd4fvry35670240000gn/T/ipykernel_85738/1358033223.py:17: DtypeWarning: Columns (12,14,18,20,22,24,26,28,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfs.append(pd.read_csv(path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Weather (Humidity+Temp) for TAS: (386362, 3)\n",
      "[OK] TAS: saved data/processed/TAS_clean.csv, shape=(254964, 6)\n",
      "[OK] Master file created: data/processed/master_data.csv (1534013, 6)\n"
     ]
    }
   ],
   "source": [
    "all_states_dfs = []\n",
    "\n",
    "for state in STATES:\n",
    "    df_state = process_state(state)\n",
    "    if df_state is not None:\n",
    "        # Ensure State column exists\n",
    "        if \"State\" not in df_state.columns:\n",
    "            df_state[\"State\"] = state\n",
    "        all_states_dfs.append(df_state)\n",
    "\n",
    "if all_states_dfs:\n",
    "    master = pd.concat(all_states_dfs, ignore_index=True)\n",
    "    master_path = os.path.join(PROCESSED_DIR, \"master_data.csv\")\n",
    "    master.to_csv(master_path, index=False)\n",
    "    print(\"[OK] Master file created:\", master_path, master.shape)\n",
    "else:\n",
    "    print(\"[WARN] No states processed; master file not created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
